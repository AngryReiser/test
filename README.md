Выполнение лабораторной работы
------------------------------

#### Цель работы

Изучение принципов работы с командным интерпретатором GNU/Linux и
основ обработки текстовых файлов с помощью команд grep, awk, sed.

#### Задание на лабораторную работу

1.  Подготовить операционную систему GNU/Linux к работе. При
    необходимости, воспользоваться средством виртуализации VMware
    Workstation/Player, Oracle VirtualBox или др. В качестве
    дистрибутива рекомендуется взять Debian или Ubuntu.

2.  Создать в домашней директории пользователя /home/user/ каталог lab1
    с помощью команды mkdir. Все скрипты и файлы создавать внутри этого
    каталога.

3.  Скопировать в каталог lab1 файл dns-tunneling.log.

4.  Ознакомиться с форматом файла dns-tunneling.log и хранящимися в нем
    данными с помощью команд cat, head, tail, more, less и т.п.

5.  Подсчитать количество записей в файле dns-tunneling.log.

6.  Вычислить номер варианта задания как остаток от деления порядкового
    номера студента по списку в журнале на количество вариантов заданий.
    Если остаток равен нулю, необходимо брать последнее задание.

7.  Написать скрипт для обработки данных из файла dns-tunneling.log в
    соответствии с вариантом задания используя исключительно команды
    командного интерпретатора bash. Использовать другие интерпретируемые
    или компилируемые языки запрещается. На вход скрипта должен
    подаваться файл dns-tunneling.log и все результаты должны
    вычисляться на его основе в реальном времени, использовать в скрипте
    заранее полученные значения запрещается.

8.  Подготовить отчет о выполнении лабораторной работы.

#### Описание текстовых данных

Файл dns-tunneling.log содержит логи DNS-сервера, представленные в
виде текстового файла, в котором каждая строка соответствует записи о
поступившем на вход сервера запросе. В логах сохраняются следующие
параметры запроса, разделенные символом табуляции:

1.  Название провайдера телекоммуникационных услуг: character array,

2.  Название узла, на котором хранятся данные: character array,

3.  Порядковый номер запроса: long,

4.  Отметка времени, когда поступил запрос: два числа long, разделенных
    точкой; первое число -- количество секунд, прошедших с 1 января 1970
    года; второе число -- количество микросекунд,

5.  IP-адрес пользователя: character array,

6.  Порт пользователя: int,

7.  Локальный IP-адрес, на который поступил запрос: character array,

8.  Локальный порт: int,

9.  Название оборудования DNS-сервера: character array,

10. Класс запроса: int,

11. Тип запроса: int,

12. Код возвращаемого значения: int,

13. Флаги: int,

14. Вспомогательный идентификатор: int,

15. Запрашиваемый URL: character array,

16. Зона: character array,

17. Вспомогательное поле 1: character array,

18. Вспомогательное поле 2: character array,

19. Вспомогательное поле 3: character array,

20. Вспомогательное поле 4: character array,

21. Ответ сервера: character array,

22. Вспомогательное поле 5: character array,

23. Вспомогательное поле 6: character array,

24. Длина ответа: int

#### Варианты заданий

1.  Написать скрипт с использованием grep, sed, awk (необходимо
    использовать не менее одной из указанных утилит; использовать все
    три необязательно) для переконвертирования данных в формат XML со
    следующей структурой:

```sh
<dnslog>
<row>
    <serial>"Порядковый номер запроса"</serial>
    <client_ip>"IP адрес пользователя"</client_ip>
    <url>"Запрашиваемый URL"</url>
</row>
<row>
    <serial>"Порядковый номер запроса"</serial>
    <client_ip>"IP адрес пользователя"</client_ip>
    <url>"Запрашиваемый URL"</url>
</row>
<row>
    ...
</row>
</dnslog>
```
> (Текст выделенный знаками "" необходимо заменить соответствующими
значениями из логов.) Сохранить в файле results.xml результат
применения написанного скрипта к последним 50 строкам файла
dns-tunneling.log.

2.  Задание аналогично варианту 1, но формат XML файла иной:
```sh
<dnslog>
<row>
    <timestamp>"Отметка времени, когда поступил запрос"</timestamp>
    <client_ip>"IP адрес пользователя"</client_ip>
    <client_port>"Порт пользователя"</client_port>
</row>
<row>
    <timestamp>"Отметка времени, когда поступил запрос"</timestamp>
    <client_ip>"IP адрес пользователя"</client_ip>
    <client_port>"Порт пользователя"</client_port>
</row>
<row>
    ...
</row>
</dnslog>
```
3.  Сформировать список уникальных IP-адресов пользователей,
    присутствующих в логах, отсортировать список в порядке увеличения
    IP-адреса и сохранить в файле results.txt. Вывести количество
    найденных уникальных IP-адресов пользователей.

Формат файла results.txt:
> <**IP адрес пользователя**>  
**\...**  
<**IP адрес пользователя**>  
<**Количество найденных уникальных IP-адресов пользователей**>

4.  Вывести на экран в формате \"ДД-MM-ГГГГ ЧЧ:мм:СС.нс\" дату и время
    поступления **первого и последнего** DNS-запросов, где ДД -- день,
    ММ -- месяц, ГГГГ -- год, ЧЧ -- час, мм -- минуты, СС -- секунды,
    нс -- наносекунды. Для этого воспользоваться командой date с
    флагом --d, например: date -d @946684800. Сохранить указанные две
    даты в файл results.txt. После этого дописать в файл results.txt
    число строк в файле dns- tunneling.log.

Формат файла results.txt:
> <**Дата и время первого DNS-запроса**>  
<**Дата и время последнего DNS-запроса**>  
<**Число строк в файле dns-tunneling.log**>

5.  Найти количество запросов, поступивших за первую, вторую и третью
    секунды ведения лога. Сохранить получившиеся три числа в файл
    results.txt. При обработке данных исходить из того, что записи в
    логе могут быть не отсортированы в порядке увеличения отметки
    времени.

Формат файла results.txt:
> <**Количество запросов за первую секунду ведения лога**>    
<**Количество запросов за вторую секунду ведения лога**>  
<**Количество запросов за третью секунду ведения лога**>

6.  Найти все доменные имена второго уровня, к которым обращались
    пользователи за все время ведения лога. Сохранить список доменов
    второго уровня в файле results.txt.

Формат файла results.txt:
> <**Доменное имя второго уровня**>  
**\...**  
<**Доменное имя второго уровня**>

7.  Подсчитать количество обращений к доменам facebook.com и google.com.
    Найти самый длинный запрошенный URL. Сохранить числа и URL в файле
    results.txt.

Формат файла results.txt:
> <**Количество обращений к facebook.com**>  
<**Количество обращений к google.com**>  
<**Самый длинный запрошенный URL**>

8.  Написать скрипт с использованием grep, sed, awk (необходимо
    использовать не менее одной из указанных утилит; использовать все
    три необязательно) для переконвертирования данных в формат JSON со
    следующей структурой:
```sh
{
    "dnslog": [
        "entry": {
            "timestamp": <Отметка времени, когда поступил запрос>, 
            "client ip": <IP адрес пользователя>,
            "url": <Запрашиваемый URL>
        },
        "entry": {
            "timestamp": <Отметка времени, когда поступил запрос>, 
            "client ip": <IP адрес пользователя>,
            "url": <Запрашиваемый URL>
        },
        ...
        ]
}
```
(Текст выделенный знаками <> необходимо заменить соответствующими значениями из логов.)  

Сохранить в файле results.json результат применения написанного
скрипта к строкам с 51 по 100-ю (включительно) файла
dns-tunneling.log.

9.  Задание аналогично предыдущему варианту, но формат JSON файла иной:
```sh
{
    <Порядковый номер запроса>: {
        "timestamp": <Отметка времени, когда поступил запрос>, 
        "client ip": <IP адрес пользователя>,
        "client port": <Порт пользователя>
    },
    <Порядковый номер запроса>: {
        "timestamp": <Отметка времени, когда поступил запрос>, 
        "client ip": <IP адрес пользователя>,
        "client port": <Порт пользователя>
    },
    ...
}
```

10.  Домены второго уровня 1yf.de. и 2yf.de. являются DNS-туннелями. Они
    используются для передачи трафика по DNS-протоколу в обход HTTP
    (например, для обхода блокировок). Подсчитать количество обращений к
    каждому из доменов второго уровня 1yf.de. и 2yf.de.. Вычислить
    среднее количество запросов в секунду по всем DNS- туннелям за
    первый час ведения логов. Сохранить полученные цифры в файле
    results.txt.

Формат файла results.txt:
> <**Количество обращений к 1yf.de.**>  
<**Количество обращений к 2yf.de.**>  
<**Cреднее кол. запросов в сек. по всем DNS- туннелям за первый час ведения
логов**>

11.  Подсчитать количество уникальных пользователей, использующих
    DNS-туннели (см. предыдущий вариант). Пользователей можно
    идентифицировать по их IP-адресам. Определить количество DNS
    --запросов, выполненных каждым из найденных пользователей. В файл
    results.tsv вывести таблицу, в которой каждая строка имеет вид:

> \<**IP-адрес**\>\<символ табуляции\>\<**количество запросов с использованием DNS- туннелей, выполненных с указанного IP-адреса**\>

12.  Вычислить в процентах, какой объем DNS трафика в приведенном логе
    приходится на DNS- туннели с разбивкой на 1yf.de. и 2yf.de. (см.
    предыдущие варианты), а также домены facebook.com. и google.com.

Формат файла results.txt:
> <**Процент трафика на DNS-туннель 1yf.de.**>  
<**Процент трафика на DNS-туннель 2yf.de.**>  
<**Процент трафика на DNS-туннель facebook.com**>  
<**Процент трафика на DNS-туннель google.com**>

#### Содержание отчета

1.  Титульный лист

2.  Цель работы

3.  Индивидуальное задание

4.  Описание входных данных

5.  Результат выполнения работы

6.  Исходный код программы с комментариями

7.  Выводы
